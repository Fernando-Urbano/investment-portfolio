The following contains a tree of the directory and all the important files of the current version of my project: 

================================================================================

FILE NAME: scripts/tree_output.txt

.
├── README.md
├── __pycache__
│   ├── config.cpython-312.pyc
│   └── run.cpython-312.pyc
├── app
│   ├── __init__.py
│   ├── __pycache__
│   │   ├── __init__.cpython-312.pyc
│   │   ├── models.cpython-312.pyc
│   │   └── routes.cpython-312.pyc
│   ├── models.py
│   ├── routes.py
│   ├── static
│   └── templates
├── config.py
├── join_files.py
├── requirements.txt
├── run.py
├── scripts
└── tests
    ├── __init__.py
    ├── __pycache__
    │   ├── __init__.cpython-312.pyc
    │   ├── conftest.cpython-312-pytest-8.3.4.pyc
    │   ├── fixtures.cpython-312.pyc
    │   ├── test_initial_database_population.cpython-312-pytest-8.3.4.pyc
    │   ├── test_save_models.cpython-312-pytest-8.3.4.pyc
    │   ├── test_save_modules.cpython-312-pytest-8.3.4.pyc
    │   └── test_timeseries.cpython-312-pytest-8.3.4.pyc
    ├── conftest.py
    ├── fixtures.py
    ├── test_initial_database_population.py
    ├── test_save_models.py
    └── test_timeseries.py

9 directories, 26 files


================================================================================

FILE NAME: scripts/migrations.txt

Migrations files:

================================================================================



================================================================================

FILE NAME: scripts/tests.txt

Test files:

================================================================================

FILE NAME: tests/conftest.py

# tests/conftest.py

import pytest
import sys
import pandas as pd
import os

# Add the project root to sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app import create_app, db


@pytest.fixture(scope='function')
def app():
    """
    Create and configure a new app instance for each test.
    """
    # Set the environment variable to 'testing'
    os.environ['FLASK_ENV'] = 'testing'
    
    # Create the Flask app with testing configuration
    app = create_app('testing')
    
    # Establish an application context
    with app.app_context():
        # Create the database and the database tables
        db.create_all()
        yield app
        # Drop the database tables after the test
        db.session.remove()
        db.drop_all()


@pytest.fixture(scope='function')
def client(app):
    """
    Create a test client for the app.
    """
    return app.test_client()


@pytest.fixture(scope='function')
def runner(app):
    """
    Create a CLI runner for the app.
    """
    return app.test_cli_runner()


# Import fixtures from fixtures.py
from .fixtures import (
    populate_test_db,
    sample_df_single_column,    
    sample_df_multiple_columns,
    create_seriesgroup_and_type  # Updated fixture name
)

================================================================================

FILE NAME: tests/test_timeseries.py

# tests/test_timeseries.py

import pytest
import datetime
import pandas as pd
from app.models import TimeSeries, DataPoint, SeriesGroup, TimeSeriesType
from app import db  # Import db for database operations


def test_from_dataframe_single_column(
    app,
    sample_df_single_column,
    create_seriesgroup_and_type  # Updated fixture name
):
    """
    Test that from_dataframe handles a single-column DataFrame and returns one TimeSeries.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    with app.app_context():
        ts_obj = TimeSeries.from_dataframe(
            df=sample_df_single_column,
            series_groups=[seriesgroup],  # Pass as a list of objects
            time_series_type=tstype  # Assign the object directly
        )

        # Expect a single TimeSeries (not a list)
        assert isinstance(ts_obj, TimeSeries), "Should return a single TimeSeries object."
        assert ts_obj.name == "price", "TimeSeries name should match the DataFrame column name."
        assert len(ts_obj.data_points) == 252, "TimeSeries should have 252 DataPoints."

        # Check the data points
        for i, dp in enumerate(ts_obj.data_points):
            expected_date = sample_df_single_column.index[i].date()
            expected_value = sample_df_single_column["price"].iloc[i]
            assert dp.date.date() == expected_date, f"Expected date {expected_date}, got {dp.date}"
            assert dp.value == expected_value, f"Expected value {expected_value}, got {dp.value}"


def test_from_dataframe_single_column_with_seriesgroup_and_tstype(
    app,
    sample_df_single_column,
    create_seriesgroup_and_type  # Updated fixture name
):
    """
    Test that from_dataframe handles a single-column DataFrame and returns one TimeSeries.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    with app.app_context():
        ts_obj = TimeSeries.from_dataframe(
            df=sample_df_single_column,
            series_groups=[seriesgroup],  # Pass as a list of objects
            time_series_type=tstype  # Assign the object directly
        )

        # Expect a single TimeSeries (not a list)
        assert isinstance(ts_obj, TimeSeries), "Should return a single TimeSeries object."
        assert ts_obj.name == "price", "TimeSeries name should match the DataFrame column name."
        assert len(ts_obj.data_points) == 252, "TimeSeries should have 252 DataPoints."

        # Check the data points
        for i, dp in enumerate(ts_obj.data_points):
            expected_date = sample_df_single_column.index[i].date()
            expected_value = sample_df_single_column["price"].iloc[i]
            assert dp.date.date() == expected_date, f"Expected date {expected_date}, got {dp.date}"
            assert dp.value == expected_value, f"Expected value {expected_value}, got {dp.value}"


def test_from_dataframe_single_column_with_date_as_column(
    app,
    sample_df_single_column,
    create_seriesgroup_and_type  # Updated fixture name
):
    """
    Test that from_dataframe handles a single-column DataFrame and returns one TimeSeries with a specified date column.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    sample_df = sample_df_single_column.copy()
    sample_df["Datetime"] = sample_df.index
    sample_df = sample_df.reset_index(drop=True)

    with app.app_context():
        ts_obj = TimeSeries.from_dataframe(
            df=sample_df,
            series_groups=[seriesgroup],  # Pass as a list of objects
            time_series_type=tstype,  # Assign the object directly
            date_column="Datetime"
        )

        # Expect a single TimeSeries (not a list)
        assert isinstance(ts_obj, TimeSeries), "Should return a single TimeSeries object."
        assert ts_obj.name == "price", "TimeSeries name should match the DataFrame column name."
        assert len(ts_obj.data_points) == 252, "TimeSeries should have 252 DataPoints."

        # Check the data points
        for i, dp in enumerate(ts_obj.data_points):
            expected_date = sample_df["Datetime"][i].date()
            expected_value = sample_df["price"].iloc[i]
            assert dp.date.date() == expected_date, f"Expected date {expected_date}, got {dp.date}"
            assert dp.value == expected_value, f"Expected value {expected_value}, got {dp.value}"


def test_from_dataframe_multi_column(
    app,
    sample_df_multiple_columns,
    create_seriesgroup_and_type  # Updated fixture name
):
    """
    Test that from_dataframe handles a multi-column DataFrame and returns multiple TimeSeries.
    """
    seriesgroup, tstype = create_seriesgroup_and_type
    num_columns = len(sample_df_multiple_columns.columns)

    with app.app_context():
        # Since there are multiple columns, provide a list of SeriesGroup objects
        # For simplicity, using the same SeriesGroup for all columns
        series_groups = [seriesgroup for _ in range(num_columns)]

        ts_objs = TimeSeries.from_dataframe(
            df=sample_df_multiple_columns,
            series_groups=series_groups,  # Pass as a list of objects
            time_series_type=tstype  # Assign the object directly
        )

        # Expect a list of TimeSeries objects
        assert isinstance(ts_objs, list), "Should return a list of TimeSeries objects."
        assert len(ts_objs) == num_columns, "Should return one TimeSeries per column."
        assert all(isinstance(ts, TimeSeries) for ts in ts_objs), "All elements should be TimeSeries objects."
        assert ts_objs[0].name == "price", "First TimeSeries name should match the first DataFrame column name."


def test_to_dataframe_multi_column(
    app,
    sample_df_multiple_columns,
    create_seriesgroup_and_type  # Updated fixture name
):
    """
    Test that from_dataframe handles a multi-column DataFrame and the resulting TimeSeries can be converted back to DataFrame.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    with app.app_context():
        # Provide a list of SeriesGroup objects matching the number of columns
        num_columns = len(sample_df_multiple_columns.columns)
        series_groups = [seriesgroup for _ in range(num_columns)]

        ts_objs = TimeSeries.from_dataframe(
            df=sample_df_multiple_columns,
            series_groups=series_groups,  # Pass as a list of objects
            time_series_type=tstype  # Assign the object directly
        )
        for ts_obj in ts_objs:
            ts_dataframe = ts_obj.to_dataframe()
            assert isinstance(ts_dataframe, pd.DataFrame), "Should return a DataFrame."
            assert len(ts_dataframe.index) == len(sample_df_multiple_columns.index), "DataFrame index length should match input length."


def test_to_dataframe_single_column(
    app,
    sample_df_single_column,
    create_seriesgroup_and_type  # Updated fixture name
):
    """
    Test that from_dataframe handles a single-column DataFrame and returns one TimeSeries, which can be converted back to DataFrame.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    with app.app_context():
        ts_obj = TimeSeries.from_dataframe(
            df=sample_df_single_column,
            series_groups=[seriesgroup],  # Pass as a list of objects
            time_series_type=tstype  # Assign the object directly
        )

        ts_dataframe = ts_obj.to_dataframe()
        assert isinstance(ts_dataframe, pd.DataFrame), "Should return a DataFrame."
        assert len(ts_dataframe.index) == len(sample_df_single_column.index), "DataFrame index length should match input length."
        assert list(ts_dataframe.columns) == ["price"], "DataFrame columns should match the input DataFrame."
        for i in range(5):
            assert ts_dataframe.iloc[i, 0] == sample_df_single_column.iloc[i, 0], "DataFrame values should match the input DataFrame."

================================================================================

FILE NAME: tests/test_initial_database_population.py

# tests/test_initial_database_population.py

import pytest
from app.models import SeriesGroup, TimeSeriesType, TimeSeries, DataPoint
import datetime

def test_initial_population(populate_test_db):
    """
    Test the initial population of the test database by verifying the created entries.
    """
    # Populate the database with 3 SeriesGroups and 5 data points per time series
    populate_test_db(num_seriesgroups=3, num_data_points=5, start_date="2024-01-01")

    # Verify the number of entries created
    assert SeriesGroup.query.count() == 3, "There should be exactly 3 SeriesGroups."
    assert TimeSeriesType.query.count() == 1, "There should be exactly one TimeSeriesType."
    assert TimeSeries.query.count() == 3, "There should be exactly three TimeSeries."
    assert DataPoint.query.count() == 15, "Each TimeSeries should have 5 DataPoints."

    # Retrieve and check the SeriesGroups
    for sg in SeriesGroup.query.all():
        assert len(sg.name) == 3, f"SeriesGroup name '{sg.name}' should have exactly three characters."
        assert sg.description.endswith("Description"), f"SeriesGroup description mismatch for '{sg.name}'."
        assert sg.series_group_code is not None and len(sg.series_group_code) == 5, (
            f"SeriesGroup '{sg.name}' should have a valid series_group_code of length 5."
        )

    # Retrieve and check the TimeSeriesType
    time_series_type = TimeSeriesType.query.first()
    assert time_series_type.name == 'Price', "TimeSeriesType name should be 'Price'."
    assert time_series_type.description == 'Price Time Series', "TimeSeriesType description mismatch."

    # Retrieve and check the TimeSeries and their DataPoints
    for time_series in TimeSeries.query.all():
        assert len(time_series.name) > 0, "TimeSeries name should not be empty."
        assert time_series.type_id == time_series_type.id, "TimeSeries type_id mismatch."

        # Ensure each TimeSeries is associated with at least one SeriesGroup
        associated_sg_ids = [sg.id for sg in time_series.series_groups]
        assert len(associated_sg_ids) >= 1, (
            f"TimeSeries '{time_series.name}' should be associated with at least one SeriesGroup."
        )

        data_points = time_series.data_points
        assert len(data_points) == 5, f"TimeSeries '{time_series.name}' should have exactly 5 DataPoints."

        # Verify the DataPoints
        start_date = datetime.date(2024, 1, 1)
        for i, dp in enumerate(data_points):
            expected_date = start_date + datetime.timedelta(days=i)
            assert dp.date == expected_date, (
                f"DataPoint date mismatch: expected {expected_date}, got {dp.date}."
            )
            assert isinstance(dp.value, float), "DataPoint 'value' should be a float."
            assert dp.time_series_id == time_series.id, (
                f"DataPoint time_series_id mismatch for DataPoint ID {dp.id}."
            )

            # Check `date_release` conditionally
            if dp.date_release:
                expected_release_date = dp.date + datetime.timedelta(days=1)
                assert dp.date_release == expected_release_date, (
                    f"DataPoint 'date_release' mismatch: expected {expected_release_date}, got {dp.date_release}."
                )

================================================================================

FILE NAME: tests/__init__.py



================================================================================

FILE NAME: tests/test_save_models.py

# tests/test_save_models.py

import pytest
import datetime
from app import db
from app.models import SeriesGroup, TimeSeriesType, TimeSeries, DataPoint

def test_save_seriesgroup(app):
    """
    Test saving a standalone SeriesGroup to the database using the `save` method.
    """
    seriesgroup = SeriesGroup(name="SG1", description="Test SeriesGroup", series_code="SG001")
    seriesgroup.save()  # or db.session.add(seriesgroup); db.session.commit()

    assert seriesgroup.id is not None, "SeriesGroup ID should be generated after saving."
    assert SeriesGroup.query.count() == 1, "Exactly one SeriesGroup should exist in the database."

    retrieved = SeriesGroup.query.first()
    assert retrieved.name == "SG1", "Retrieved SeriesGroup name should match 'SG1'."
    assert retrieved.description == "Test SeriesGroup", "SeriesGroup description should match."
    assert retrieved.series_code == "SG001", "SeriesGroup series_code should match 'SG001'."

def test_save_time_series_type(app):
    """
    Test saving a TimeSeriesType to the database using the `save` method.
    """
    tst = TimeSeriesType(name="Price", description="Price Time Series")
    tst.save()

    assert tst.id is not None, "TimeSeriesType ID should be set after saving."
    assert TimeSeriesType.query.count() == 1, "Exactly one TimeSeriesType should exist."

    retrieved = TimeSeriesType.query.first()
    assert retrieved.name == "Price", "Retrieved name should be 'Price'."
    assert retrieved.description == "Price Time Series", "TimeSeriesType description mismatch."

def test_save_time_series_with_dependencies(app):
    """
    Test saving a TimeSeries that depends on a SeriesGroup and a TimeSeriesType.
    Verifies the parent objects can be saved together if they're new.
    """
    seriesgroup = SeriesGroup(name="SG2", description="Second SeriesGroup", series_code="SG002")
    tstype = TimeSeriesType(name="Volume", description="Volume Time Series")

    ts = TimeSeries(
        name="TS-Test",
        time_series_type=tstype  # Correct: Assign the object, not the ID
    )
    ts.series_groups.append(seriesgroup)

    ts.save()  # Should save ts, seriesgroup & tstype, too.

    # Verify TimeSeries
    assert ts.id is not None, "TimeSeries ID should be set after saving."
    assert TimeSeries.query.count() == 1, "One TimeSeries should exist."

    # Verify SeriesGroup
    assert seriesgroup.id is not None, "SeriesGroup ID should be set after saving TimeSeries."
    assert SeriesGroup.query.count() == 1, "One SeriesGroup should exist."

    # Verify TimeSeriesType
    assert tstype.id is not None, "TimeSeriesType ID should be set after saving TimeSeries."
    assert TimeSeriesType.query.count() == 1, "One TimeSeriesType should exist."
    
    # Additionally, check that the association is correct
    retrieved_ts = TimeSeries.query.first()
    associated_sgs = retrieved_ts.series_groups.all()
    assert len(associated_sgs) == 1, "TimeSeries should be associated with one SeriesGroup."
    assert associated_sgs[0].id == seriesgroup.id, "Associated SeriesGroup should match the created one."

def test_save_data_points_with_timeseries(app):
    """
    Test saving a TimeSeries along with multiple DataPoints.
    Ensures child DataPoints are also saved.
    """
    seriesgroup = SeriesGroup(name="SG3", description="Third SeriesGroup", series_code="SG003")
    tstype = TimeSeriesType(name="Price", description="Price Time Series")

    ts = TimeSeries(name="TS-DataPoints", time_series_type=tstype)  # Correct assignment
    ts.series_groups.append(seriesgroup)

    dp1 = DataPoint(date=datetime.date(2025, 1, 10), value=4000.0)
    dp2 = DataPoint(date=datetime.date(2025, 1, 11), value=4050.5)
    ts.data_points.extend([dp1, dp2])

    ts.save()  # Should save ts, seriesgroup, tstype, and dp1/dp2

    # Verify
    assert TimeSeries.query.count() == 1, "One TimeSeries should be saved."
    assert DataPoint.query.count() == 2, "Two DataPoints should be saved."

    retrieved_ts = TimeSeries.query.first()
    assert len(retrieved_ts.data_points) == 2, "Retrieved TimeSeries should have 2 DataPoints."
    
    # Verify SeriesGroup association
    associated_sgs = retrieved_ts.series_groups.all()
    assert len(associated_sgs) == 1, "TimeSeries should be associated with one SeriesGroup."
    assert associated_sgs[0].id == seriesgroup.id, "Associated SeriesGroup should match the created one."

def test_save_datapoint_alone_with_parents(app):
    """
    Test saving a single DataPoint that has a reference to a new TimeSeries,
    which references a new SeriesGroup and TimeSeriesType. All should be saved.
    """
    seriesgroup = SeriesGroup(name="SG4", description="Fourth SeriesGroup", series_code="SG004")
    tstype = TimeSeriesType(name="Bids", description="Bid Time Series")
    ts = TimeSeries(name="TS-Bids", time_series_type=tstype)  # Correct assignment
    ts.series_groups.append(seriesgroup)

    dp = DataPoint(date=datetime.date(2025, 1, 12), value=5001.5, time_series=ts)
    dp.save()  # Should cascade and save dp, ts, seriesgroup, tstype

    assert dp.id is not None, "DataPoint should have an ID after saving."
    assert seriesgroup.id is not None, "SeriesGroup should be saved."
    assert tstype.id is not None, "TimeSeriesType should be saved."
    assert ts.id is not None, "TimeSeries should be saved."

    # Verify counts
    assert SeriesGroup.query.count() == 1, "Exactly one SeriesGroup should be in DB."
    assert TimeSeriesType.query.count() == 1, "Exactly one TimeSeriesType should be in DB."
    assert TimeSeries.query.count() == 1, "Exactly one TimeSeries should be in DB."
    assert DataPoint.query.count() == 1, "Exactly one DataPoint should be in DB."

    # Optionally, verify the association
    retrieved_ts = TimeSeries.query.first()
    associated_sgs = retrieved_ts.series_groups.all()
    assert len(associated_sgs) == 1, "TimeSeries should be associated with one SeriesGroup."
    assert associated_sgs[0].id == seriesgroup.id, "Associated SeriesGroup should match the created one."

def test_save_multiple_objects_in_one_session(app):
    """
    Test saving multiple objects in one transaction without committing until the end.
    """
    seriesgroup = SeriesGroup(name="SG5", description="Fifth SeriesGroup", series_code="SG005")
    tstype = TimeSeriesType(name="Spread", description="Spread Time Series")
    ts = TimeSeries(name="TS-Spread", time_series_type=tstype)  # Correct assignment
    ts.series_groups.append(seriesgroup)
    dp = DataPoint(date=datetime.date(2025, 1, 13), value=3999.9, time_series=ts)

    # Manually pass commit=False to gather them in the session, then commit once
    seriesgroup.save(commit=False)
    tstype.save(commit=False)
    ts.save(commit=False)
    dp.save(commit=False)

    # Now commit explicitly
    db.session.commit()

    # Verify
    assert SeriesGroup.query.count() == 1, "Exactly one SeriesGroup should be saved."
    assert TimeSeriesType.query.count() == 1, "Exactly one TimeSeriesType should be saved."
    assert TimeSeries.query.count() == 1, "Exactly one TimeSeries should be saved."
    assert DataPoint.query.count() == 1, "Exactly one DataPoint should be saved."

    retrieved_dp = DataPoint.query.first()
    assert retrieved_dp.value == 3999.9, "DataPoint value should be as assigned."
    assert retrieved_dp.time_series.name == "TS-Spread", "DataPoint should link to the correct TimeSeries."

================================================================================

FILE NAME: tests/fixtures.py

# tests/fixtures.py

import pytest
import random
import string
from app.models import SeriesGroup, TimeSeriesType, TimeSeries, DataPoint
import datetime
import pandas as pd
from app import db
import numpy as np


@pytest.fixture
def create_seriesgroup_and_type(app):
    """
    Fixture to create a SeriesGroup and a TimeSeriesType.
    Returns the objects themselves.
    """
    seriesgroup = SeriesGroup(name="SG_Test", description="Test SeriesGroup", series_group_code="SG999")
    tstype = TimeSeriesType(name="TestType", description="Test TimeSeriesType")
    db.session.add_all([seriesgroup, tstype])
    db.session.commit()
    return seriesgroup, tstype

@pytest.fixture
def populate_test_db(app):
    """
    Fixture to populate the test database with initial data.
    Accepts parameters for the number of series groups and data points per time series.
    """

    def _populate_test_db(num_seriesgroups=3, num_data_points=5, start_date=datetime.date(2024, 1, 1)):
        """
        Internal function to populate the test database.
        
        Args:
            num_seriesgroups (int): Number of SeriesGroups to create.
            num_data_points (int): Number of data points per time series.
            start_date (date or str): Start date for generating data points.
        """

        # Convert `start_date` to a `datetime.date` object if it's a string
        if isinstance(start_date, str):
            start_date = datetime.datetime.strptime(start_date, "%Y-%m-%d").date()

        def generate_random_name(length=3):
            """Generate a random name with the specified length."""
            return ''.join(random.choices(string.ascii_uppercase, k=length))

        def create_data_points(time_series_id, num_points, start_date):
            """Create random data points for a given time series."""
            data_points = []
            for i in range(num_points):
                date = start_date + datetime.timedelta(days=i)
                value = round(random.uniform(1000.0, 5000.0), 2)  # Random value between 1000 and 5000

                # Randomly decide whether to assign a `date_release` or leave it as None
                if random.choice([True, False]):
                    date_release = date + datetime.timedelta(days=1)
                else:
                    date_release = None

                data_point = DataPoint(
                    date=date,
                    value=value,
                    date_release=date_release,
                    time_series_id=time_series_id
                )
                data_points.append(data_point)
            return data_points

        with app.app_context():
            # Set a fixed random seed for reproducibility
            random.seed(42)

            # Create a TimeSeriesType
            time_series_type = TimeSeriesType(name='Price', description='Price Time Series')
            db.session.add(time_series_type)
            db.session.commit()

            # Generate the specified number of SeriesGroups and time series
            for _ in range(num_seriesgroups):
                # Create a random SeriesGroup
                seriesgroup_name = generate_random_name()
                series_group_code = ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))
                seriesgroup = SeriesGroup(
                    name=seriesgroup_name,
                    description=f"{seriesgroup_name} Description",
                    series_group_code=series_group_code
                )
                db.session.add(seriesgroup)
                db.session.commit()

                # Create a random TimeSeries for the SeriesGroup
                time_series_name = generate_random_name()
                time_series = TimeSeries(
                    name=f"{seriesgroup_name} {time_series_name}",
                    type_id=time_series_type.id,
                    delta_type='pct'  # Assuming default or desired value
                )
                db.session.add(time_series)
                db.session.commit()

                # Associate TimeSeries with SeriesGroup
                seriesgroup.series.append(time_series)
                db.session.commit()

                # Create random data points for the time series
                data_points = create_data_points(time_series.id, num_data_points, start_date)
                db.session.add_all(data_points)
                db.session.commit()

    return _populate_test_db

@pytest.fixture
def sample_df_single_column():
    """
    Returns a single-column DataFrame (with a DateTimeIndex).
    """
    rng = np.random.default_rng(seed=42)
    returns = rng.normal(0.0001, 0.01, 252)
    prices = 100 * (1 + np.cumsum(returns))
    dates = pd.date_range("2025-01-01", periods=252, freq="D")
    return pd.DataFrame({"price": prices}, index=dates)

@pytest.fixture
def sample_df_multiple_columns():
    """
    Returns a multi-column DataFrame (with a DateTimeIndex).
    """
    rng = np.random.default_rng(seed=42)
    returns = rng.normal(0.0001, 0.01, 252)
    prices = 100 * (1 + np.cumsum(returns))
    volumes = rng.integers(1000, 10000, 252)
    dates = pd.date_range("2025-01-01", periods=252, freq="D")
    return pd.DataFrame({"price": prices, "volume": volumes}, index=dates)

================================================================================



================================================================================

FILE NAME: scripts/app.txt

App files:

================================================================================

FILE NAME: app/models.py

# app/models.py

from app import db
import pandas as pd
from sqlalchemy.sql import func
import datetime
import re

# Association table for many-to-many relationship between SeriesGroup and SeriesBase
seriesgroup_seriesbase = db.Table(
    'seriesgroup_seriesbase',
    db.Column('seriesgroup_id', db.Integer, db.ForeignKey('series_group.id'), primary_key=True),
    db.Column('seriesbase_id', db.Integer, db.ForeignKey('series_base.id'), primary_key=True)
)

# Association table for many-to-many relationship between SeriesBase and Keyword
seriesbase_keyword = db.Table(
    'seriesbase_keyword',
    db.Column('seriesbase_id', db.Integer, db.ForeignKey('series_base.id'), primary_key=True),
    db.Column('keyword_id', db.Integer, db.ForeignKey('keyword.id'), primary_key=True)
)

class BaseModel(db.Model):
    __abstract__ = True

    def save(self, session=None, commit=True):
        """
        Saves the current instance to the database, ensuring any dependent objects are also saved.
        session (db.session): The SQLAlchemy session to use. If None, uses db.session.
        commit (bool): Whether or not to commit immediately.
        """
        if session is None:
            session = db.session

        self._save_dependencies(session)

        session.add(self)

        if commit:
            session.commit()

    def _save_dependencies(self, session):
        """
        Override this in child classes to save any dependencies (parents or children).
        Default implementation does nothing.
        """
        pass

class Keyword(BaseModel):
    __tablename__ = 'keyword'
    id = db.Column(db.Integer, primary_key=True)
    word = db.Column(db.String(50), unique=True, nullable=False, index=True)

    # Relationship to SeriesBase
    series = db.relationship(
        'SeriesBase',
        secondary=seriesbase_keyword,
        back_populates='keywords',
        lazy='dynamic'
    )

    def __repr__(self):
        return f'<Keyword {self.word}>'

class SeriesBase(BaseModel):
    __tablename__ = 'series_base'
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(100), nullable=False)
    description = db.Column(db.String(200))
    type = db.Column(db.String(50))  # Discriminator column

    date_create = db.Column(db.DateTime(timezone=True), server_default=func.now(), nullable=False)
    date_update = db.Column(
        db.DateTime(timezone=True), server_default=func.now(),
        onupdate=func.now(), nullable=False
    )

    def __init__(self, name, description=None, keywords=None, **kwargs):
        """
        Initializes a SeriesBase instance.

        Parameters:
        - name (str): The name of the series.
        - description (str, optional): A description of the series.
        - keywords (list of str, optional): A list of keyword strings to associate with the series.
        - **kwargs: Additional keyword arguments for other fields.
        """
        super().__init__(**kwargs)
        self.name = name
        self.description = description
        if keywords:
            for keyword_word in keywords:
                self.add_keyword(keyword_word)

    # Many-to-Many relationship with Keyword
    keywords = db.relationship(
        'Keyword',
        secondary=seriesbase_keyword,
        back_populates='series',
        lazy='dynamic'
    )

    __mapper_args__ = {
        'polymorphic_identity': 'series_base',
        'polymorphic_on': type,
        'with_polymorphic': '*'
    }

    def __repr__(self):
        return f'<SeriesBase {self.name}>'

    def add_keyword(self, keyword_word):
        """
        Adds a keyword to the series. Creates the keyword if it doesn't exist.
        """
        keyword = Keyword.query.filter_by(word=keyword_word).first()
        if not keyword:
            keyword = Keyword(word=keyword_word)
            db.session.add(keyword)
        if not self.keywords.filter_by(word=keyword_word).first():
            self.keywords.append(keyword)

    def remove_keyword(self, keyword_word):
        """
        Removes a keyword from the series.
        """
        keyword = Keyword.query.filter_by(word=keyword_word).first()
        if keyword and self.keywords.filter_by(word=keyword_word).first():
            self.keywords.remove(keyword)

class SeriesGroup(SeriesBase):
    __tablename__ = 'series_group'
    id = db.Column(db.Integer, db.ForeignKey('series_base.id'), primary_key=True)
    series_group_code = db.Column(db.String(5), nullable=False, unique=True)  # Renamed and kept unique

    # Self-referential relationship for nested SeriesGroups
    parent_id = db.Column(db.Integer, db.ForeignKey('series_group.id'), nullable=True)
    children = db.relationship(
        'SeriesGroup',
        backref=db.backref('parent', remote_side=[id]),
        lazy='dynamic',
        foreign_keys=[parent_id]  # Explicitly specify foreign_keys
    )

    # Many-to-many relationship with SeriesBase (TimeSeries and SeriesGroup)
    series = db.relationship(
        'SeriesBase',
        secondary=seriesgroup_seriesbase,
        backref=db.backref('series_groups', lazy='dynamic'),
        lazy='dynamic'
    )

    __mapper_args__ = {
        'polymorphic_identity': 'series_group',
    }

    def __repr__(self):
        return f'<SeriesGroup {self.name}>'

class TimeSeries(SeriesBase):
    __tablename__ = 'time_series'
    id = db.Column(db.Integer, db.ForeignKey('series_base.id'), primary_key=True)
    time_series_code = db.Column(db.String(10), nullable=False, unique=True)  # New unique field
    type_id = db.Column(db.Integer, db.ForeignKey('time_series_type.id'), nullable=False)
    delta_type = db.Column(db.String(10), nullable=True, default='pct')

    data_points = db.relationship('DataPoint', backref='time_series', lazy=True)

    __mapper_args__ = {
        'polymorphic_identity': 'time_series',
    }

    def _save_dependencies(self, session):
        """
        Ensures the related TimeSeriesType and DataPoint objects are also saved.
        """
        # Save the parent TimeSeriesType if it's new or modified
        if self.time_series_type:
            session.add(self.time_series_type)

        # Save child DataPoints
        for dp in self.data_points:
            session.add(dp)

    def to_dataframe(
            self,
            only_most_recent_per_date=True,
            filter_date_release_smaller_or_equal_to=None,
            include_date_release=False,
            include_date_create=False
        ):
        """
        Returns the TimeSeries data as a pandas DataFrame.
        """
        data = {
            'date': [dp.date for dp in self.data_points],
            'value': [dp.value for dp in self.data_points],
            'date_create': [dp.date_create for dp in self.data_points],
            'date_release': [dp.date_release for dp in self.data_points]
        }
        ts_dataframe = (
            pd.DataFrame(data)
            .sort_values(['date', 'date_release', 'date_create'])
        )
        if only_most_recent_per_date:
            ts_dataframe = ts_dataframe.drop_duplicates(subset=['date'])
        ts_dataframe = (
            ts_dataframe
            .set_index('date')
            .rename({'value': self.name}, axis=1)
        )
        if filter_date_release_smaller_or_equal_to is not None:
            if isinstance(filter_date_release_smaller_or_equal_to, str):
                try:
                    filter_date = pd.to_datetime(filter_date_release_smaller_or_equal_to)
                except ValueError:
                    raise ValueError("filter_date_release_smaller_or_equal_to must be a valid date string.")
            elif not isinstance(filter_date_release_smaller_or_equal_to, (datetime.datetime, datetime.date)):
                raise ValueError("filter_date_release_smaller_or_equal_to must be a valid date string.")
            else:
                filter_date = filter_date_release_smaller_or_equal_to
            ts_dataframe = ts_dataframe[ts_dataframe['date_release'] <= filter_date]
        
        if not include_date_release:
            ts_dataframe = ts_dataframe.drop(columns=['date_release'])
        if not include_date_create:
            ts_dataframe = ts_dataframe.drop(columns=['date_create'])
        return ts_dataframe

    @classmethod
    def from_dataframe(
        cls,
        df,
        series_groups=None,
        time_series_type=None,
        name=None,
        description=None,
        date_column=None,
        all_columns_have_same_series_groups=False
    ):
        """
        Creates one or more TimeSeries objects from a pandas DataFrame without saving to the database.

        Returns
        -------
        TimeSeries or List[TimeSeries]
            A single TimeSeries if exactly one column is processed, or a list of multiple TimeSeries objects.
        """
        if date_column is not None:
            if date_column not in df.columns:
                raise ValueError(f"Date column '{date_column}' not found in DataFrame.")
            df = df.set_index(date_column)

        if 'date' in [c.lower() for c in df.columns.tolist()]:
            df = df.set_index('date')
        try:
            df.index = pd.to_datetime(df.index)
        except ValueError:
            raise ValueError("The DataFrame must have a datetime index or specify a date_column.")
        df.index.name = 'date'

        if len(df.columns) == 1:
            if name is None:
                name = df.columns[0]

            # Allow series_groups to be optional
            if series_groups is not None:
                if isinstance(description, list):
                    description = description[0]
            else:
                if description is None:
                    description = ""
            
            return cls.build_time_series_object(
                df.iloc[:, 0].values,
                df.index,
                name,
                series_groups,  # Can be None
                time_series_type,
                description
            )
        else:
            if name is None:
                name = df.columns
            elif name and not isinstance(name, list):
                raise ValueError("Name must be a list if multiple columns are provided.")
            elif len(name) != len(df.columns):
                raise ValueError("Name list must match the number of columns in the DataFrame.")
            else:
                raise ValueError("Name must be provided as list")
            
            # Allow series_groups to be optional
            if series_groups is not None:
                if isinstance(series_groups, (str, int, SeriesGroup)):
                    series_groups = [series_groups] * len(df.columns)
                elif not isinstance(series_groups, list):
                    raise ValueError("SeriesGroups must be provided as list, string, or SeriesGroup instances")
                    
                if len(series_groups) != len(df.columns):
                    if not all_columns_have_same_series_groups:
                        raise ValueError(
                            "SeriesGroups list must match the number of columns in the DataFrame or "
                            + "parameter 'all_columns_have_same_series_groups=True'."
                        )
            else:
                series_groups = [None] * len(df.columns)  # No groups associated

            if isinstance(description, str) and description is not None:
                raise ValueError("Description must be a list if multiple columns are provided.")
            
            if not all([g is None for g in series_groups]) and all_columns_have_same_series_groups:
                all_columns_have_same_series_groups = True
                col_series_groups = series_groups
            else:
                all_columns_have_same_series_groups = False


            all_columns_have_same_series_groups = (
                False if all([g is None for g in series_groups]) else all_columns_have_same_series_groups
            )

            all_time_series = []
            for i, col in enumerate(df.columns):
                if not all_columns_have_same_series_groups:
                    col_series_groups = series_groups[i]
                all_time_series.append(
                    cls.build_time_series_object(
                    df[col].values,
                    df.index,
                    name[i],
                    col_series_groups,
                    time_series_type,
                    description
                ))
            return all_time_series

    @classmethod
    def save_from_dataframe(cls,
        df,
        series_groups=None,
        time_series_type=None,
        name=None,
        description=None,
        date_column=None,
        value_columns=None,
    ):
        """
        Creates one or more TimeSeries objects from a pandas DataFrame and saves them to the database.

        Returns
        -------
        TimeSeries or List[TimeSeries]
            A single TimeSeries if exactly one column is processed, or a list of multiple TimeSeries objects.
        """
        time_series_objects = cls.from_dataframe(
            df,
            series_groups,
            time_series_type,
            name,
            description,
            date_column,
            value_columns
        )
        if isinstance(time_series_objects, list):
            for ts in time_series_objects:
                ts.save()
        else:
            time_series_objects.save()
        return True

    @classmethod
    def build_time_series_object(cls, values, dates, time_series_name, series_groups, time_series_type, description=None):
        """
        Build a TimeSeries object with DataPoint objects from provided values and dates.
        """
        data_points = []
        for i in range(len(values)):
            data_points.append(DataPoint(date=dates[i], value=values[i]))
        ts = cls(
            name=time_series_name,
            data_points=data_points
        )
        if description is not None:
            ts.description = description
        if isinstance(time_series_type, TimeSeriesType):
            ts.time_series_type = time_series_type
        else:
            ts.type_id = time_series_type

        # Associate with SeriesGroups if provided
        if series_groups:
            if isinstance(series_groups, SeriesGroup):
                ts.series_groups.append(series_groups)
            elif isinstance(series_groups, list):
                for sg in series_groups:
                    if sg is not None:
                        ts.series_groups.append(sg)
            else:
                raise ValueError("series_groups must be a SeriesGroup instance, list of SeriesGroup instances, or None")

        return ts

class DataPoint(BaseModel):
    __tablename__ = 'data_point'
    id = db.Column(db.Integer, primary_key=True)
    date = db.Column(db.Date, nullable=False)
    value = db.Column(db.Float, nullable=False)
    date_release = db.Column(db.Date, nullable=True)
    time_series_id = db.Column(db.Integer, db.ForeignKey('time_series.id'), nullable=False)

    date_create = db.Column(db.DateTime(timezone=True), server_default=func.now(), nullable=False)
    date_update = db.Column(
        db.DateTime(timezone=True), server_default=func.now(),
        onupdate=func.now(), nullable=False
    )

    def __repr__(self):
        return f'<DataPoint {self.date}: {self.value}>'

    def _save_dependencies(self, session):
        """
        Ensure the parent TimeSeries (and potentially its parent objects) are saved.
        """
        if self.time_series:
            # Make sure the parent TimeSeries saves its dependencies too.
            # This will also add the SeriesGroups and any other DataPoints.
            self.time_series._save_dependencies(session)
            session.add(self.time_series)

class TimeSeriesType(BaseModel):
    __tablename__ = 'time_series_type'
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(50), nullable=False, unique=True)
    description = db.Column(db.String(200))
    time_series = db.relationship('TimeSeries', backref='time_series_type', lazy=True)

    date_create = db.Column(
        db.DateTime(timezone=True), server_default=func.now(),
        nullable=False
    )
    date_update = db.Column(
        db.DateTime(timezone=True), server_default=func.now(),
        onupdate=func.now(), nullable=False
    )

    __mapper_args__ = {
        'polymorphic_identity': 'time_series_type',
    }

    def __repr__(self):
        return f'<TimeSeriesType {self.name}>'

================================================================================

FILE NAME: app/__init__.py

from flask import Flask
from flask_sqlalchemy import SQLAlchemy
from config import config  # Import the config dictionary
from flask_migrate import Migrate
import os

db = SQLAlchemy()
migrate = Migrate()

def create_app(config_name=None):
    app = Flask(__name__)
    
    # Determine the configuration to use
    if config_name is None:
        config_name = os.getenv('FLASK_ENV') or 'default'
    
    # Use the configuration class from the config dictionary
    app.config.from_object(config[config_name])
    
    # Initialize extensions
    db.init_app(app)
    migrate.init_app(app, db)
    
    # Import and register Blueprints
    from .routes import main
    app.register_blueprint(main)
    
    with app.app_context():
        from . import models
    
    return app

================================================================================

FILE NAME: app/routes.py

from flask import Blueprint

# Define the Blueprint
main = Blueprint('main', __name__)

@main.route('/')
def home():
    return "Welcome to the Investment Portfolio App!"

================================================================================



================================================================================

