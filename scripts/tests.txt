Test files:

================================================================================

FILE NAME: tests/conftest.py

# tests/conftest.py

import pytest
import sys
import pandas as pd
import os

# Add the project root to sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app import create_app, db


@pytest.fixture(scope='function')
def app():
    """
    Create and configure a new app instance for each test.
    """
    # Set the environment variable to 'testing'
    os.environ['FLASK_ENV'] = 'testing'
    
    # Create the Flask app with testing configuration
    app = create_app('testing')
    
    # Establish an application context
    with app.app_context():
        # Create the database and the database tables
        db.create_all()
        yield app
        # Drop the database tables after the test
        db.session.remove()
        db.drop_all()


@pytest.fixture(scope='function')
def client(app):
    """
    Create a test client for the app.
    """
    return app.test_client()


@pytest.fixture(scope='function')
def runner(app):
    """
    Create a CLI runner for the app.
    """
    return app.test_cli_runner()


# Import fixtures from fixtures.py
from .fixtures import (
    populate_test_db,
    sample_df_single_column,    
    sample_df_multiple_columns,
    create_seriesgroup_and_type  # Updated fixture name
)

================================================================================

FILE NAME: tests/test_keywords.py

# tests/test_keywords.py

import pytest
from sqlalchemy.exc import IntegrityError, InvalidRequestError
from sqlalchemy.orm import joinedload
from sqlalchemy import select
from app.models import SeriesGroup, Keyword, SeriesBase
from app import db

@pytest.fixture
def seriesgroup(app):
    """
    Fixture to create a SeriesGroup without keywords.
    """
    sg = SeriesGroup(
        name="SG_Test",
        description="Test SeriesGroup",
        series_group_code="SG999"
    )
    sg.save()
    return sg

def test_add_keywords_during_creation(app):
    """
    Test creating a SeriesGroup and adding keywords after saving.
    Verify that keywords are saved and associated correctly.
    """
    keywords = ["Finance", "Investment", "Portfolio"]
    sg = SeriesGroup(
        name="SG_WithKeywords",
        description="SeriesGroup with initial keywords",
        series_group_code="SG100"
        # Do not pass keywords here to avoid DetachedInstanceError
    )
    sg.save()

    # Now, add keywords after the object is bound to the session
    for kw in keywords:
        sg.add_keyword(kw)
    sg.save()

    # Retrieve the SeriesGroup from the database with keywords eagerly loaded
    stmt = select(SeriesGroup).options(joinedload(SeriesGroup.keywords)).where(SeriesGroup.id == sg.id)
    retrieved_sg = db.session.execute(stmt).scalars().unique().one()

    assert retrieved_sg is not None, "SeriesGroup should be saved and retrievable."

    # Verify keywords are associated
    associated_keywords = [kw.word for kw in retrieved_sg.keywords]
    assert set(associated_keywords) == set(keywords), "Keywords should match the ones provided during creation."

def test_add_keywords_later(app, seriesgroup):
    """
    Test adding keywords to a SeriesGroup after it has been created.
    Verify that keywords are saved and associated correctly.
    """
    # Initially, the SeriesGroup has no keywords
    stmt = select(SeriesGroup).options(joinedload(SeriesGroup.keywords)).where(SeriesGroup.id == seriesgroup.id)
    retrieved_sg = db.session.execute(stmt).scalars().unique().one()
    assert len(retrieved_sg.keywords) == 0, "SeriesGroup should initially have no keywords."

    # Add keywords
    new_keywords = ["Stocks", "Bonds"]
    for kw in new_keywords:
        retrieved_sg.add_keyword(kw)

    # Save the changes
    retrieved_sg.save()

    # Retrieve again with eager loading
    retrieved_sg = db.session.execute(stmt).scalars().unique().one()

    # Verify keywords are associated
    associated_keywords = [kw.word for kw in retrieved_sg.keywords]
    assert set(associated_keywords) == set(new_keywords), "Keywords should match the ones added later."

def test_add_duplicate_keywords(app, seriesgroup):
    """
    Test that adding duplicate keywords does not create duplicate entries in the database.
    """
    keyword = "Equity"
    # Add the keyword for the first time
    seriesgroup.add_keyword(keyword)
    seriesgroup.save()

    # Attempt to add the same keyword again
    seriesgroup.add_keyword(keyword)
    seriesgroup.save()

    # Retrieve with eager loading
    stmt = select(SeriesGroup).options(joinedload(SeriesGroup.keywords)).where(SeriesGroup.id == seriesgroup.id)
    retrieved_sg = db.session.execute(stmt).scalars().unique().one()

    # Verify only one instance of the keyword exists
    assert len(retrieved_sg.keywords) == 1, "Duplicate keywords should not be added."
    assert retrieved_sg.keywords[0].word == keyword, "Keyword should match the one added."

def test_add_invalid_keyword_length(app, seriesgroup):
    """
    Test that adding a keyword exceeding the maximum length raises a ValueError.
    """
    invalid_keyword = "K" * 51  # Exceeds the 50 character limit

    with pytest.raises(ValueError) as exc_info:
        # Attempt to add an overly long keyword
        seriesgroup.add_keyword(invalid_keyword)
        seriesgroup.save()
    # No need to rollback since the exception is handled

    assert "Keyword must be 50 characters or less." in str(exc_info.value), \
        "Adding a keyword with invalid length should raise a ValueError."

def test_remove_keyword(app, seriesgroup):
    """
    Test removing a keyword from a SeriesGroup.
    """
    keywords = ["Growth", "Value", "Income"]
    for kw in keywords:
        seriesgroup.add_keyword(kw)
    seriesgroup.save()

    # Retrieve with eager loading
    stmt = select(SeriesGroup).options(joinedload(SeriesGroup.keywords)).where(SeriesGroup.id == seriesgroup.id)
    retrieved_sg = db.session.execute(stmt).scalars().unique().one()

    assert len(retrieved_sg.keywords) == 3, "SeriesGroup should have three keywords initially."

    # Remove one keyword
    retrieved_sg.remove_keyword("Value")
    retrieved_sg.save()

    # Retrieve again with eager loading
    retrieved_sg = db.session.execute(stmt).scalars().unique().one()

    # Verify the keyword is removed
    associated_keywords = [kw.word for kw in retrieved_sg.keywords]
    assert "Value" not in associated_keywords, "Keyword 'Value' should be removed."
    assert len(retrieved_sg.keywords) == 2, "SeriesGroup should have two keywords after removal."

def test_add_keyword_with_invalid_type(app, seriesgroup):
    """
    Test that adding a keyword with an invalid type (non-string) raises a TypeError.
    """
    invalid_keyword = 12345  # Non-string keyword

    with pytest.raises(TypeError) as exc_info:
        # Attempt to add a non-string keyword
        seriesgroup.add_keyword(invalid_keyword)
        seriesgroup.save()
    # No need to rollback since the exception is handled

    assert "Keyword must be a string." in str(exc_info.value), \
        "Adding a keyword with invalid type should raise a TypeError."

def test_save_and_retrieve_keywords(app):
    """
    Test saving a SeriesGroup with keywords and retrieving it to verify persistence.
    """
    keywords = ["Alpha", "Beta", "Gamma"]
    sg = SeriesGroup(
        name="SG_Persistence",
        description="SeriesGroup for persistence test",
        series_group_code="SG200"
        # Do not pass keywords here to avoid DetachedInstanceError
    )
    sg.save()

    # Now, add keywords after the object is bound to the session
    for kw in keywords:
        sg.add_keyword(kw)
    sg.save()

    # Retrieve the SeriesGroup from the database with keywords eagerly loaded
    stmt = select(SeriesGroup).options(joinedload(SeriesGroup.keywords)).where(SeriesGroup.id == sg.id)
    retrieved_sg = db.session.execute(stmt).scalars().unique().one()

    assert retrieved_sg is not None, "SeriesGroup should be retrievable after saving."

    # Verify keywords are persisted
    associated_keywords = [kw.word for kw in retrieved_sg.keywords]
    assert set(associated_keywords) == set(keywords), "Persisted keywords should match the ones saved."

def test_save_keywords_added_later(app, seriesgroup):
    """
    Test saving keywords added after the initial creation and verifying persistence.
    """
    # Add keywords after creation
    keywords = ["Delta", "Epsilon"]
    for kw in keywords:
        seriesgroup.add_keyword(kw)
    seriesgroup.save()

    # Retrieve the SeriesGroup with keywords eagerly loaded
    stmt = select(SeriesGroup).options(joinedload(SeriesGroup.keywords)).where(SeriesGroup.id == seriesgroup.id)
    retrieved_sg = db.session.execute(stmt).scalars().unique().one()

    assert retrieved_sg is not None, "SeriesGroup should be retrievable after adding keywords."

    # Verify keywords are persisted
    associated_keywords = [kw.word for kw in retrieved_sg.keywords]
    assert set(associated_keywords) == set(keywords), "Persisted keywords should match the ones added later."

================================================================================

FILE NAME: tests/test_timeseries.py

# tests/test_timeseries.py

import random
import string
import pytest
import datetime
import pandas as pd
from app.models import TimeSeries, DataPoint, SeriesGroup, TimeSeriesType
from app import db  # Import db for database operations


def test_from_dataframe_single_column(
    app,
    sample_df_single_column,
    create_seriesgroup_and_type  # Updated fixture name
):
    """
    Test that from_dataframe handles a single-column DataFrame and returns one TimeSeries.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    with app.app_context():
        ts_obj = TimeSeries.from_dataframe(
            df=sample_df_single_column,
            code='AAPL',  # Add a code for the TimeSeries
            series_groups=[seriesgroup],  # Pass as a list of objects
            time_series_type=tstype  # Assign the object directly
        )

        # Expect a single TimeSeries (not a list)
        assert isinstance(ts_obj, TimeSeries), "Should return a single TimeSeries object."
        assert ts_obj.name == "price", "TimeSeries name should match the DataFrame column name."
        assert len(ts_obj.data_points) == 252, "TimeSeries should have 252 DataPoints."

        # Check the data points
        for i, dp in enumerate(ts_obj.data_points):
            expected_date = sample_df_single_column.index[i].date()
            expected_value = sample_df_single_column["price"].iloc[i]
            assert dp.date.date() == expected_date, f"Expected date {expected_date}, got {dp.date}"
            assert dp.value == expected_value, f"Expected value {expected_value}, got {dp.value}"


def test_from_dataframe_single_column_with_seriesgroup_and_tstype(
    app,
    sample_df_single_column,
    create_seriesgroup_and_type  # Updated fixture name
):
    """
    Test that from_dataframe handles a single-column DataFrame and returns one TimeSeries.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    with app.app_context():
        ts_obj = TimeSeries.from_dataframe(
            df=sample_df_single_column,
            code='AAPL',
            series_groups=[seriesgroup],  # Pass as a list of objects
            time_series_type=tstype  # Assign the object directly
        )

        # Expect a single TimeSeries (not a list)
        assert isinstance(ts_obj, TimeSeries), "Should return a single TimeSeries object."
        assert ts_obj.name == "price", "TimeSeries name should match the DataFrame column name."
        assert len(ts_obj.data_points) == 252, "TimeSeries should have 252 DataPoints."

        # Check the data points
        for i, dp in enumerate(ts_obj.data_points):
            expected_date = sample_df_single_column.index[i].date()
            expected_value = sample_df_single_column["price"].iloc[i]
            assert dp.date.date() == expected_date, f"Expected date {expected_date}, got {dp.date}"
            assert dp.value == expected_value, f"Expected value {expected_value}, got {dp.value}"


def test_from_dataframe_single_column_with_date_as_column(
    app,
    sample_df_single_column,
    create_seriesgroup_and_type  # Updated fixture name
):
    """
    Test that from_dataframe handles a single-column DataFrame and returns one TimeSeries with a specified date column.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    sample_df = sample_df_single_column.copy()
    sample_df["Datetime"] = sample_df.index
    sample_df = sample_df.reset_index(drop=True)

    with app.app_context():
        ts_obj = TimeSeries.from_dataframe(
            df=sample_df,
            series_groups=[seriesgroup],  # Pass as a list of objects
            time_series_type=tstype,  # Assign the object directly
            code='AAPL',
            date_column="Datetime"
        )

        # Expect a single TimeSeries (not a list)
        assert isinstance(ts_obj, TimeSeries), "Should return a single TimeSeries object."
        assert ts_obj.name == "price", "TimeSeries name should match the DataFrame column name."
        assert len(ts_obj.data_points) == 252, "TimeSeries should have 252 DataPoints."

        # Check the data points
        for i, dp in enumerate(ts_obj.data_points):
            expected_date = sample_df["Datetime"][i].date()
            expected_value = sample_df["price"].iloc[i]
            assert dp.date.date() == expected_date, f"Expected date {expected_date}, got {dp.date}"
            assert dp.value == expected_value, f"Expected value {expected_value}, got {dp.value}"


def test_from_dataframe_multi_column(
    app,
    sample_df_multiple_columns,
    create_seriesgroup_and_type  # Updated fixture name
):
    """
    Test that from_dataframe handles a multi-column DataFrame and returns multiple TimeSeries.
    """
    seriesgroup, tstype = create_seriesgroup_and_type
    num_columns = len(sample_df_multiple_columns.columns)

    with app.app_context():
        # Since there are multiple columns, provide a list of SeriesGroup objects
        # For simplicity, using the same SeriesGroup for all columns
        series_groups = [seriesgroup for _ in range(num_columns)]
        codes = [''.join(random.choices(string.ascii_uppercase, k=3)) for _ in range(num_columns)]

        ts_objs = TimeSeries.from_dataframe(
            df=sample_df_multiple_columns,
            series_groups=series_groups,  # Pass as a list of objects
            time_series_type=tstype,  # Assign the object directly
            code=codes  # Add a code for all TimeSeries
        )

        # Expect a list of TimeSeries objects
        assert isinstance(ts_objs, list), "Should return a list of TimeSeries objects."
        assert len(ts_objs) == num_columns, "Should return one TimeSeries per column."
        assert all(isinstance(ts, TimeSeries) for ts in ts_objs), "All elements should be TimeSeries objects."
        assert ts_objs[0].name == "price", "First TimeSeries name should match the first DataFrame column name."


def test_to_dataframe_multi_column(
    app,
    sample_df_multiple_columns,
    create_seriesgroup_and_type  # Updated fixture name
):
    """
    Test that from_dataframe handles a multi-column DataFrame and the resulting TimeSeries can be converted back to DataFrame.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    with app.app_context():
        # Provide a list of SeriesGroup objects matching the number of columns
        num_columns = len(sample_df_multiple_columns.columns)
        series_groups = [seriesgroup for _ in range(num_columns)]
        codes = [''.join(random.choices(string.ascii_uppercase, k=3)) for _ in range(num_columns)]

        ts_objs = TimeSeries.from_dataframe(
            df=sample_df_multiple_columns,
            series_groups=series_groups,  # Pass as a list of objects
            time_series_type=tstype,  # Assign the object directly
            code=codes  # Add a code for all TimeSeries
        )
        for ts_obj in ts_objs:
            ts_dataframe = ts_obj.to_dataframe()
            assert isinstance(ts_dataframe, pd.DataFrame), "Should return a DataFrame."
            assert len(ts_dataframe.index) == len(sample_df_multiple_columns.index), "DataFrame index length should match input length."


def test_to_dataframe_single_column(
    app,
    sample_df_single_column,
    create_seriesgroup_and_type  # Updated fixture name
):
    """
    Test that from_dataframe handles a single-column DataFrame and returns one TimeSeries, which can be converted back to DataFrame.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    with app.app_context():
        ts_obj = TimeSeries.from_dataframe(
            df=sample_df_single_column,
            series_groups=[seriesgroup],  # Pass as a list of objects
            time_series_type=tstype,  # Assign the object directly
            code='AAPL'
        )

        ts_dataframe = ts_obj.to_dataframe()
        assert isinstance(ts_dataframe, pd.DataFrame), "Should return a DataFrame."
        assert len(ts_dataframe.index) == len(sample_df_single_column.index), "DataFrame index length should match input length."
        assert list(ts_dataframe.columns) == ["price"], "DataFrame columns should match the input DataFrame."
        for i in range(5):
            assert ts_dataframe.iloc[i, 0] == sample_df_single_column.iloc[i, 0], "DataFrame values should match the input DataFrame."

================================================================================

FILE NAME: tests/test_initial_database_population.py

# tests/test_initial_database_population.py

import pytest
from app.models import SeriesGroup, TimeSeriesType, TimeSeries, DataPoint
import datetime

def test_initial_population(populate_test_db):
    """
    Test the initial population of the test database by verifying the created entries.
    """
    # Populate the database with 3 SeriesGroups and 5 data points per time series
    populate_test_db(num_seriesgroups=3, num_data_points=5, start_date="2024-01-01")

    # Verify the number of entries created
    assert SeriesGroup.query.count() == 3, "There should be exactly 3 SeriesGroups."
    assert TimeSeriesType.query.count() == 1, "There should be exactly one TimeSeriesType."
    assert TimeSeries.query.count() == 3, "There should be exactly three TimeSeries."
    assert DataPoint.query.count() == 15, "Each TimeSeries should have 5 DataPoints."

    # Retrieve and check the SeriesGroups
    for sg in SeriesGroup.query.all():
        assert len(sg.name) == 3, f"SeriesGroup name '{sg.name}' should have exactly three characters."
        assert sg.description.endswith("Description"), f"SeriesGroup description mismatch for '{sg.name}'."
        assert sg.series_group_code is not None and len(sg.series_group_code) == 5, (
            f"SeriesGroup '{sg.name}' should have a valid series_group_code of length 5."
        )

    # Retrieve and check the TimeSeriesType
    time_series_type = TimeSeriesType.query.first()
    assert time_series_type.name == 'Price', "TimeSeriesType name should be 'Price'."
    assert time_series_type.description == 'Price Time Series', "TimeSeriesType description mismatch."

    # Retrieve and check the TimeSeries and their DataPoints
    for time_series in TimeSeries.query.all():
        assert len(time_series.name) > 0, "TimeSeries name should not be empty."
        assert time_series.type_id == time_series_type.id, "TimeSeries type_id mismatch."

        # Ensure each TimeSeries is associated with at least one SeriesGroup
        associated_sg_ids = [sg.id for sg in time_series.series_groups]
        assert len(associated_sg_ids) >= 1, (
            f"TimeSeries '{time_series.name}' should be associated with at least one SeriesGroup."
        )

        data_points = time_series.data_points
        assert len(data_points) == 5, f"TimeSeries '{time_series.name}' should have exactly 5 DataPoints."

        # Verify the DataPoints
        start_date = datetime.date(2024, 1, 1)
        for i, dp in enumerate(data_points):
            expected_date = start_date + datetime.timedelta(days=i)
            assert dp.date == expected_date, (
                f"DataPoint date mismatch: expected {expected_date}, got {dp.date}."
            )
            assert isinstance(dp.value, float), "DataPoint 'value' should be a float."
            assert dp.time_series_id == time_series.id, (
                f"DataPoint time_series_id mismatch for DataPoint ID {dp.id}."
            )

            # Check `date_release` conditionally
            if dp.date_release:
                expected_release_date = dp.date + datetime.timedelta(days=1)
                assert dp.date_release == expected_release_date, (
                    f"DataPoint 'date_release' mismatch: expected {expected_release_date}, got {dp.date_release}."
                )

================================================================================

FILE NAME: tests/__init__.py



================================================================================

FILE NAME: tests/test_relationships.py

# tests/test_relationships.py

import pytest
import datetime
from app import db
from app.models import SeriesGroup, TimeSeries, SeriesBase, TimeSeriesType, Keyword, DataPoint

@pytest.fixture
def create_parent_child_seriesgroups(app):
    """
    Fixture to create a parent SeriesGroup with multiple child SeriesGroups.
    """
    parent = SeriesGroup(name="ParentSG", description="Parent SeriesGroup", series_group_code="PSG001")
    child1 = SeriesGroup(name="ChildSG1", description="First Child SeriesGroup", series_group_code="CSG001", parent=parent)
    child2 = SeriesGroup(name="ChildSG2", description="Second Child SeriesGroup", series_group_code="CSG002", parent=parent)
    db.session.add_all([parent, child1, child2])
    db.session.commit()
    return parent, child1, child2

def test_seriesgroup_parent_child_relationship(app, create_parent_child_seriesgroups):
    """
    Test the self-referential parent-child relationship in SeriesGroup.
    """
    parent, child1, child2 = create_parent_child_seriesgroups

    # Verify parent has two children
    assert len(parent.children.all()) == 2, "Parent SeriesGroup should have two children."
    assert child1.parent == parent, "Child1's parent should be ParentSG."
    assert child2.parent == parent, "Child2's parent should be ParentSG."

    # Verify children are correctly linked
    assert child1 in parent.children.all(), "Child1 should be in ParentSG's children."
    assert child2 in parent.children.all(), "Child2 should be in ParentSG's children."

def test_polymorphic_querying(app):
    """
    Test that querying SeriesBase returns instances of the correct subclasses.
    """
    tstype = TimeSeriesType(name="Polymorphic", description="Polymorphic TimeSeriesType")

    # Create a SeriesGroup
    sg = SeriesGroup(name="SG_Poly", description="Polymorphic SeriesGroup", series_group_code="SGP001")
    db.session.add(sg)

    # Create a TimeSeries
    ts = TimeSeries(name="TS_Poly", time_series_type=tstype, code="TSP001")
    db.session.add(ts)

    db.session.commit()

    # Query SeriesBase
    all_seriesbase = SeriesBase.query.all()
    assert len(all_seriesbase) == 2, "There should be three SeriesBase instances."
    
    # Optionally, verify the types of each instance
    assert any(isinstance(sb, SeriesGroup) for sb in all_seriesbase), "At least one SeriesGroup should be present."
    assert any(isinstance(sb, TimeSeries) for sb in all_seriesbase), "At least one TimeSeries should be present."

def test_seriesgroup_seriesbase_association(app, create_seriesgroup_and_type):
    """
    Test the many-to-many relationship between SeriesGroup and SeriesBase.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    # Create additional SeriesBase instances
    ts1 = TimeSeries(name="TS_Assoc1", time_series_type=tstype, code="TSA001")
    ts2 = TimeSeries(name="TS_Assoc2", time_series_type=tstype, code="TSA002")
    db.session.add_all([ts1, ts2])
    db.session.commit()

    # Associate SeriesBase with SeriesGroup
    seriesgroup.series.append(ts1)
    seriesgroup.series.append(ts2)
    db.session.commit()

    # Verify associations
    assert ts1 in seriesgroup.series.all(), "TS_Assoc1 should be associated with SeriesGroup."
    assert ts2 in seriesgroup.series.all(), "TS_Assoc2 should be associated with SeriesGroup."
    assert seriesgroup in ts1.series_groups.all(), "SeriesGroup should be associated with TS_Assoc1."
    assert seriesgroup in ts2.series_groups.all(), "SeriesGroup should be associated with TS_Assoc2."

def test_keyword_uniqueness(app, create_seriesgroup_and_type):
    """
    Test that adding duplicate keywords raises an IntegrityError.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    # Add a keyword
    keyword = Keyword(word="Finance")
    db.session.add(keyword)
    db.session.commit()

    # Attempt to add the same keyword again
    duplicate_keyword = Keyword(word="Finance")
    db.session.add(duplicate_keyword)

    with pytest.raises(Exception) as exc_info:
        db.session.commit()

    db.session.rollback()
    assert 'UNIQUE constraint failed' in str(exc_info.value), "Adding duplicate keyword should fail due to unique constraint."

def test_seriesgroup_unique_code(app, create_seriesgroup_and_type):
    """
    Test that SeriesGroup's series_group_code is unique.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    # Create a SeriesGroup with a unique code
    sg_unique = SeriesGroup(name="UniqueSG", description="Unique Code SeriesGroup", series_group_code="USG001")
    db.session.add(sg_unique)
    db.session.commit()

    # Attempt to create another SeriesGroup with the same code
    sg_duplicate = SeriesGroup(name="DuplicateSG", description="Duplicate Code SeriesGroup", series_group_code="USG001")
    db.session.add(sg_duplicate)

    with pytest.raises(Exception) as exc_info:
        db.session.commit()

    db.session.rollback()
    assert 'UNIQUE constraint failed' in str(exc_info.value), "Adding SeriesGroup with duplicate code should fail due to unique constraint."

def test_time_series_unique_code(app, create_seriesgroup_and_type):
    """
    Test that TimeSeries's time_series_code is unique.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    # Create a TimeSeries with a unique code
    ts_unique = TimeSeries(name="UniqueTS", time_series_type=tstype, code="UTS001")
    db.session.add(ts_unique)
    db.session.commit()

    # Attempt to create another TimeSeries with the same code
    ts_duplicate = TimeSeries(name="DuplicateTS", time_series_type=tstype, code="UTS001")
    db.session.add(ts_duplicate)

    with pytest.raises(Exception) as exc_info:
        db.session.commit()

    db.session.rollback()
    assert 'UNIQUE constraint failed' in str(exc_info.value), "Adding TimeSeries with duplicate code should fail due to unique constraint."

def test_seriesbase_deletion_cascade(app, create_seriesgroup_and_type):
    """
    Test that deleting a SeriesBase (TimeSeries) also deletes associated DataPoints if cascade is set.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    # Create a TimeSeries with DataPoints
    ts = TimeSeries(name="TS_DeleteCascade", time_series_type=tstype, code="TSC001")
    dp1 = DataPoint(date=datetime.date(2025, 1, 1), value=100.0, time_series=ts)
    dp2 = DataPoint(date=datetime.date(2025, 1, 2), value=110.0, time_series=ts)
    db.session.add_all([ts, dp1, dp2])
    db.session.commit()

    # Verify DataPoints exist
    assert DataPoint.query.filter_by(time_series_id=ts.id).count() == 2, "There should be two DataPoints associated with the TimeSeries."

    # Delete the TimeSeries
    db.session.delete(ts)
    db.session.commit()

    # Verify TimeSeries is deleted
    assert TimeSeries.query.filter_by(id=ts.id).count() == 0, "TimeSeries should be deleted."

    # Verify DataPoints are also deleted if cascade is set
    # Note: Ensure that cascade delete is configured in the relationship if expected
    assert DataPoint.query.filter_by(time_series_id=ts.id).count() == 0, "Associated DataPoints should be deleted with the TimeSeries."

def test_validate_code_len_decorator(app, create_seriesgroup_and_type):
    """
    Test that the validate_code_len decorator enforces code length constraints.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    # Attempt to create a SeriesGroup with a code exceeding CODE_MAX_LEN
    long_code = 'A' * 13  # Assuming CODE_MAX_LEN is 12

    with pytest.raises(ValueError) as exc_info:
        sg = SeriesGroup(name="LongCodeSG", description="SeriesGroup with long code", series_group_code=long_code)
        sg.save()

    db.session.rollback()
    assert "Code must be 12 characters or less." in str(exc_info.value), "Code length validation should fail for codes longer than 12 characters."

def test_seriesgroup_nested_relationship(app, create_seriesgroup_and_type):
    """
    Test creating nested SeriesGroups (grandchildren).
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    # Create child SeriesGroups
    child1 = SeriesGroup(name="ChildSG1", description="First Child SeriesGroup", series_group_code="CSG001", parent=seriesgroup)
    child2 = SeriesGroup(name="ChildSG2", description="Second Child SeriesGroup", series_group_code="CSG002", parent=seriesgroup)
    db.session.add_all([child1, child2])
    db.session.commit()

    # Create grandchildren
    grandchild1 = SeriesGroup(name="GrandChildSG1", description="First Grandchild SeriesGroup", series_group_code="GCSG001", parent=child1)
    grandchild2 = SeriesGroup(name="GrandChildSG2", description="Second Grandchild SeriesGroup", series_group_code="GCSG002", parent=child1)
    db.session.add_all([grandchild1, grandchild2])
    db.session.commit()

    # Verify relationships
    assert grandchild1.parent == child1, "Grandchild1's parent should be ChildSG1."
    assert grandchild2.parent == child1, "Grandchild2's parent should be ChildSG1."
    assert child1 in seriesgroup.children.all(), "ChildSG1 should be a child of ParentSG."
    assert grandchild1 in child1.children.all(), "GrandChildSG1 should be a child of ChildSG1."
    assert grandchild2 in child1.children.all(), "GrandChildSG2 should be a child of ChildSG1."

def test_seriesbase_keywords_relationship(app, create_seriesgroup_and_type):
    """
    Test that SeriesBase (SeriesGroup and TimeSeries) can have multiple keywords associated.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    # Add keywords to SeriesGroup
    seriesgroup.add_keyword("Finance")
    seriesgroup.add_keyword("Investment")
    db.session.commit()

    # Verify keywords
    assert len(seriesgroup.keywords) == 2, "SeriesGroup should have two keywords."
    keywords = [kw.word for kw in seriesgroup.keywords]
    assert "Finance" in keywords, "SeriesGroup should have the 'Finance' keyword."
    assert "Investment" in keywords, "SeriesGroup should have the 'Investment' keyword."

    # Create a TimeSeries and add keywords
    ts = TimeSeries(name="TS_Keywords", time_series_type=tstype, code="TSK001")
    ts.add_keyword("Growth")
    ts.add_keyword("Value")
    db.session.add(ts)
    db.session.commit()

    # Verify keywords
    assert len(ts.keywords) == 2, "TimeSeries should have two keywords."
    ts_keywords = [kw.word for kw in ts.keywords]
    assert "Growth" in ts_keywords, "TimeSeries should have the 'Growth' keyword."
    assert "Value" in ts_keywords, "TimeSeries should have the 'Value' keyword."

def test_datapoint_date_release_logic(app, create_seriesgroup_and_type):
    """
    Test the conditional assignment of date_release in DataPoint.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    # Create a TimeSeries
    ts = TimeSeries(name="TS_DateRelease", time_series_type=tstype, code="TSD001")
    db.session.add(ts)
    db.session.commit()

    # Create DataPoints with and without date_release
    dp1 = DataPoint(date=datetime.date(2025, 1, 1), value=100.0, date_release=datetime.date(2025, 1, 2), time_series=ts)
    dp2 = DataPoint(date=datetime.date(2025, 1, 3), value=110.0, time_series=ts)  # No date_release
    db.session.add_all([dp1, dp2])
    db.session.commit()

    # Verify date_release
    assert dp1.date_release == datetime.date(2025, 1, 2), "DataPoint1's date_release should be set correctly."
    assert dp2.date_release is None, "DataPoint2's date_release should be None."

def test_seriesbase_unique_constraints(app, create_seriesgroup_and_type):
    """
    Test unique constraints on SeriesGroup and TimeSeries.
    """
    seriesgroup, tstype = create_seriesgroup_and_type

    # Create a SeriesGroup with a unique code
    sg1 = SeriesGroup(name="SG_Unique1", description="Unique SeriesGroup 1", series_group_code="SGU001")
    db.session.add(sg1)
    db.session.commit()

    # Attempt to create another SeriesGroup with the same code
    sg2 = SeriesGroup(name="SG_Unique2", description="Unique SeriesGroup 2", series_group_code="SGU001")
    db.session.add(sg2)

    with pytest.raises(Exception) as exc_info:
        db.session.commit()

    db.session.rollback()
    assert 'UNIQUE constraint failed' in str(exc_info.value), "Duplicate SeriesGroup codes should violate unique constraint."

    # Similarly, test TimeSeries unique code
    ts1 = TimeSeries(name="TS_Unique1", time_series_type=tstype, code="TSU001")
    db.session.add(ts1)
    db.session.commit()

    ts2 = TimeSeries(name="TS_Unique2", time_series_type=tstype, code="TSU001")
    db.session.add(ts2)

    with pytest.raises(Exception) as exc_info_ts:
        db.session.commit()

    db.session.rollback()
    assert 'UNIQUE constraint failed' in str(exc_info_ts.value), "Duplicate TimeSeries codes should violate unique constraint."

================================================================================

FILE NAME: tests/test_save_models.py

# tests/test_save_models.py

import pytest
import datetime
from app import db
from app.models import SeriesGroup, TimeSeriesType, TimeSeries, DataPoint

def test_save_seriesgroup(app):
    """
    Test saving a standalone SeriesGroup to the database using the `save` method.
    """
    seriesgroup = SeriesGroup(name="SG1", description="Test SeriesGroup", code="SG001")
    seriesgroup.save()  # or db.session.add(seriesgroup); db.session.commit()

    assert seriesgroup.id is not None, "SeriesGroup ID should be generated after saving."
    assert SeriesGroup.query.count() == 1, "Exactly one SeriesGroup should exist in the database."

    retrieved = SeriesGroup.query.first()
    assert retrieved.name == "SG1", "Retrieved SeriesGroup name should match 'SG1'."
    assert retrieved.description == "Test SeriesGroup", "SeriesGroup description should match."
    assert retrieved.series_group_code == "SG001", "SeriesGroup series_group_code should match 'SG001'."

def test_save_time_series_type(app):
    """
    Test saving a TimeSeriesType to the database using the `save` method.
    """
    tst = TimeSeriesType(name="Price", description="Price Time Series")
    tst.save()

    assert tst.id is not None, "TimeSeriesType ID should be set after saving."
    assert TimeSeriesType.query.count() == 1, "Exactly one TimeSeriesType should exist."

    retrieved = TimeSeriesType.query.first()
    assert retrieved.name == "Price", "Retrieved name should be 'Price'."
    assert retrieved.description == "Price Time Series", "TimeSeriesType description mismatch."

def test_save_time_series_with_dependencies(app):
    """
    Test saving a TimeSeries that depends on a SeriesGroup and a TimeSeriesType.
    Verifies the parent objects can be saved together if they're new.
    """
    seriesgroup = SeriesGroup(name="SG2", description="Second SeriesGroup", series_group_code="SG002")
    tstype = TimeSeriesType(name="Volume", description="Volume Time Series")

    ts = TimeSeries(
        name="TS-Test",
        time_series_type=tstype,  # Correct: Assign the object, not the ID
        code="TST"
    )
    ts.series_groups.append(seriesgroup)

    ts.save()  # Should save ts, seriesgroup & tstype, too.

    # Verify TimeSeries
    assert ts.id is not None, "TimeSeries ID should be set after saving."
    assert TimeSeries.query.count() == 1, "One TimeSeries should exist."

    # Verify SeriesGroup
    assert seriesgroup.id is not None, "SeriesGroup ID should be set after saving TimeSeries."
    assert SeriesGroup.query.count() == 1, "One SeriesGroup should exist."

    # Verify TimeSeriesType
    assert tstype.id is not None, "TimeSeriesType ID should be set after saving TimeSeries."
    assert TimeSeriesType.query.count() == 1, "One TimeSeriesType should exist."
    
    # Additionally, check that the association is correct
    retrieved_ts = TimeSeries.query.first()
    associated_sgs = retrieved_ts.series_groups.all()
    assert len(associated_sgs) == 1, "TimeSeries should be associated with one SeriesGroup."
    assert associated_sgs[0].id == seriesgroup.id, "Associated SeriesGroup should match the created one."

def test_save_data_points_with_timeseries(app):
    """
    Test saving a TimeSeries along with multiple DataPoints.
    Ensures child DataPoints are also saved.
    """
    seriesgroup = SeriesGroup(name="SG3", description="Third SeriesGroup", series_group_code="SG003")
    tstype = TimeSeriesType(name="Price", description="Price Time Series")

    ts = TimeSeries(name="TS-DataPoints", time_series_type=tstype, code="109")  # Correct assignment
    ts.series_groups.append(seriesgroup)

    dp1 = DataPoint(date=datetime.date(2025, 1, 10), value=4000.0)
    dp2 = DataPoint(date=datetime.date(2025, 1, 11), value=4050.5)
    ts.data_points.extend([dp1, dp2])

    ts.save()  # Should save ts, seriesgroup, tstype, and dp1/dp2

    # Verify
    assert TimeSeries.query.count() == 1, "One TimeSeries should be saved."
    assert DataPoint.query.count() == 2, "Two DataPoints should be saved."

    retrieved_ts = TimeSeries.query.first()
    assert len(retrieved_ts.data_points) == 2, "Retrieved TimeSeries should have 2 DataPoints."
    
    # Verify SeriesGroup association
    associated_sgs = retrieved_ts.series_groups.all()
    assert len(associated_sgs) == 1, "TimeSeries should be associated with one SeriesGroup."
    assert associated_sgs[0].id == seriesgroup.id, "Associated SeriesGroup should match the created one."

def test_save_datapoint_alone_with_parents(app):
    """
    Test saving a single DataPoint that has a reference to a new TimeSeries,
    which references a new SeriesGroup and TimeSeriesType. All should be saved.
    """
    seriesgroup = SeriesGroup(name="SG4", description="Fourth SeriesGroup", series_group_code="SG004")
    tstype = TimeSeriesType(name="Bids", description="Bid Time Series")
    ts = TimeSeries(name="TS-Bids", time_series_type=tstype, code="1291")  # Correct assignment
    ts.series_groups.append(seriesgroup)

    dp = DataPoint(date=datetime.date(2025, 1, 12), value=5001.5, time_series=ts)
    dp.save()  # Should cascade and save dp, ts, seriesgroup, tstype

    assert dp.id is not None, "DataPoint should have an ID after saving."
    assert seriesgroup.id is not None, "SeriesGroup should be saved."
    assert tstype.id is not None, "TimeSeriesType should be saved."
    assert ts.id is not None, "TimeSeries should be saved."

    # Verify counts
    assert SeriesGroup.query.count() == 1, "Exactly one SeriesGroup should be in DB."
    assert TimeSeriesType.query.count() == 1, "Exactly one TimeSeriesType should be in DB."
    assert TimeSeries.query.count() == 1, "Exactly one TimeSeries should be in DB."
    assert DataPoint.query.count() == 1, "Exactly one DataPoint should be in DB."

    # Optionally, verify the association
    retrieved_ts = TimeSeries.query.first()
    associated_sgs = retrieved_ts.series_groups.all()
    assert len(associated_sgs) == 1, "TimeSeries should be associated with one SeriesGroup."
    assert associated_sgs[0].id == seriesgroup.id, "Associated SeriesGroup should match the created one."

def test_save_multiple_objects_in_one_session(app):
    """
    Test saving multiple objects in one transaction without committing until the end.
    """
    seriesgroup = SeriesGroup(name="SG5", description="Fifth SeriesGroup", series_group_code="SG005")
    tstype = TimeSeriesType(name="Spread", description="Spread Time Series")
    ts = TimeSeries(name="TS-Spread", time_series_type=tstype, code="183")  # Correct assignment
    ts.series_groups.append(seriesgroup)
    dp = DataPoint(date=datetime.date(2025, 1, 13), value=3999.9, time_series=ts)

    # Manually pass commit=False to gather them in the session, then commit once
    seriesgroup.save(commit=False)
    tstype.save(commit=False)
    ts.save(commit=False)
    dp.save(commit=False)

    # Now commit explicitly
    db.session.commit()

    # Verify
    assert SeriesGroup.query.count() == 1, "Exactly one SeriesGroup should be saved."
    assert TimeSeriesType.query.count() == 1, "Exactly one TimeSeriesType should be saved."
    assert TimeSeries.query.count() == 1, "Exactly one TimeSeries should be saved."
    assert DataPoint.query.count() == 1, "Exactly one DataPoint should be saved."

    retrieved_dp = DataPoint.query.first()
    assert retrieved_dp.value == 3999.9, "DataPoint value should be as assigned."
    assert retrieved_dp.time_series.name == "TS-Spread", "DataPoint should link to the correct TimeSeries."

================================================================================

FILE NAME: tests/fixtures.py

# tests/fixtures.py

import pytest
import random
import string
from app.models import SeriesGroup, TimeSeriesType, TimeSeries, DataPoint
import datetime
import pandas as pd
from app import db
import numpy as np


@pytest.fixture
def create_seriesgroup_and_type(app):
    """
    Fixture to create a SeriesGroup and a TimeSeriesType.
    Returns the objects themselves.
    """
    seriesgroup = SeriesGroup(name="SG_Test", description="Test SeriesGroup", series_group_code="SG999")
    tstype = TimeSeriesType(name="TestType", description="Test TimeSeriesType")
    db.session.add_all([seriesgroup, tstype])
    db.session.commit()
    return seriesgroup, tstype

@pytest.fixture
def populate_test_db(app):
    """
    Fixture to populate the test database with initial data.
    Accepts parameters for the number of series groups and data points per time series.
    """

    def _populate_test_db(num_seriesgroups=3, num_data_points=5, start_date=datetime.date(2024, 1, 1)):
        """
        Internal function to populate the test database.
        
        Args:
            num_seriesgroups (int): Number of SeriesGroups to create.
            num_data_points (int): Number of data points per time series.
            start_date (date or str): Start date for generating data points.
        """

        # Convert `start_date` to a `datetime.date` object if it's a string
        if isinstance(start_date, str):
            start_date = datetime.datetime.strptime(start_date, "%Y-%m-%d").date()

        def generate_random_name(length=3):
            """Generate a random name with the specified length."""
            return ''.join(random.choices(string.ascii_uppercase, k=length))

        def create_data_points(time_series_id, num_points, start_date):
            """Create random data points for a given time series."""
            data_points = []
            for i in range(num_points):
                date = start_date + datetime.timedelta(days=i)
                value = round(random.uniform(1000.0, 5000.0), 2)  # Random value between 1000 and 5000

                # Randomly decide whether to assign a `date_release` or leave it as None
                if random.choice([True, False]):
                    date_release = date + datetime.timedelta(days=1)
                else:
                    date_release = None

                data_point = DataPoint(
                    date=date,
                    value=value,
                    date_release=date_release,
                    time_series_id=time_series_id
                )
                data_points.append(data_point)
            return data_points

        with app.app_context():
            # Set a fixed random seed for reproducibility
            random.seed(42)

            # Create a TimeSeriesType
            time_series_type = TimeSeriesType(name='Price', description='Price Time Series')
            db.session.add(time_series_type)
            db.session.commit()

            # Generate the specified number of SeriesGroups and time series
            for _ in range(num_seriesgroups):
                # Create a random SeriesGroup
                seriesgroup_name = generate_random_name()
                series_group_code = ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))
                seriesgroup = SeriesGroup(
                    name=seriesgroup_name,
                    description=f"{seriesgroup_name} Description",
                    series_group_code=series_group_code
                )
                db.session.add(seriesgroup)
                db.session.commit()

                # Create a random TimeSeries for the SeriesGroup
                time_series_name = generate_random_name()
                time_series = TimeSeries(
                    name=f"{seriesgroup_name} {time_series_name}",
                    type_id=time_series_type.id,
                    delta_type='pct',  # Assuming default or desired value
                    code=series_group_code + time_series_name[0].upper()
                )
                db.session.add(time_series)
                db.session.commit()

                # Associate TimeSeries with SeriesGroup
                seriesgroup.series.append(time_series)
                db.session.commit()

                # Create random data points for the time series
                data_points = create_data_points(time_series.id, num_data_points, start_date)
                db.session.add_all(data_points)
                db.session.commit()

    return _populate_test_db

@pytest.fixture
def sample_df_single_column():
    """
    Returns a single-column DataFrame (with a DateTimeIndex).
    """
    rng = np.random.default_rng(seed=42)
    returns = rng.normal(0.0001, 0.01, 252)
    prices = 100 * (1 + np.cumsum(returns))
    dates = pd.date_range("2025-01-01", periods=252, freq="D")
    return pd.DataFrame({"price": prices}, index=dates)

@pytest.fixture
def sample_df_multiple_columns():
    """
    Returns a multi-column DataFrame (with a DateTimeIndex).
    """
    rng = np.random.default_rng(seed=42)
    returns = rng.normal(0.0001, 0.01, 252)
    prices = 100 * (1 + np.cumsum(returns))
    volumes = rng.integers(1000, 10000, 252)
    dates = pd.date_range("2025-01-01", periods=252, freq="D")
    return pd.DataFrame({"price": prices, "volume": volumes}, index=dates)

================================================================================

